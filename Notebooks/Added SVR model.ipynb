{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18513,"sourceType":"datasetVersion","datasetId":13720}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.045333Z","iopub.execute_input":"2025-06-22T09:15:41.045744Z","iopub.status.idle":"2025-06-22T09:15:41.051589Z","shell.execute_reply.started":"2025-06-22T09:15:41.045719Z","shell.execute_reply":"2025-06-22T09:15:41.050349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/insurance/insurance.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.159615Z","iopub.execute_input":"2025-06-22T09:15:41.159986Z","iopub.status.idle":"2025-06-22T09:15:41.179731Z","shell.execute_reply.started":"2025-06-22T09:15:41.159959Z","shell.execute_reply":"2025-06-22T09:15:41.178662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info() #to check if there's null values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.229656Z","iopub.execute_input":"2025-06-22T09:15:41.229962Z","iopub.status.idle":"2025-06-22T09:15:41.243016Z","shell.execute_reply.started":"2025-06-22T09:15:41.229940Z","shell.execute_reply":"2025-06-22T09:15:41.241953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.350101Z","iopub.execute_input":"2025-06-22T09:15:41.350428Z","iopub.status.idle":"2025-06-22T09:15:41.362976Z","shell.execute_reply.started":"2025-06-22T09:15:41.350404Z","shell.execute_reply":"2025-06-22T09:15:41.361909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.364797Z","iopub.execute_input":"2025-06-22T09:15:41.365128Z","iopub.status.idle":"2025-06-22T09:15:41.401350Z","shell.execute_reply.started":"2025-06-22T09:15:41.365102Z","shell.execute_reply":"2025-06-22T09:15:41.400308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.histplot(df['charges'], kde=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.402841Z","iopub.execute_input":"2025-06-22T09:15:41.403167Z","iopub.status.idle":"2025-06-22T09:15:41.692481Z","shell.execute_reply.started":"2025-06-22T09:15:41.403146Z","shell.execute_reply":"2025-06-22T09:15:41.691362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.pairplot(df)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:41.693957Z","iopub.execute_input":"2025-06-22T09:15:41.694275Z","iopub.status.idle":"2025-06-22T09:15:45.626049Z","shell.execute_reply.started":"2025-06-22T09:15:41.694248Z","shell.execute_reply":"2025-06-22T09:15:45.624929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-Hot Encoding for Categorical Variables\nCate_cols = ['sex', 'smoker', 'region']\ndf = pd.get_dummies(df, columns= Cate_cols, drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:45.627292Z","iopub.execute_input":"2025-06-22T09:15:45.627614Z","iopub.status.idle":"2025-06-22T09:15:45.639872Z","shell.execute_reply.started":"2025-06-22T09:15:45.627588Z","shell.execute_reply":"2025-06-22T09:15:45.638740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#defining features and targets \nX = df.drop('charges',axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:45.642773Z","iopub.execute_input":"2025-06-22T09:15:45.643126Z","iopub.status.idle":"2025-06-22T09:15:45.660692Z","shell.execute_reply.started":"2025-06-22T09:15:45.643100Z","shell.execute_reply":"2025-06-22T09:15:45.659647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y=df['charges']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:45.661996Z","iopub.execute_input":"2025-06-22T09:15:45.662332Z","iopub.status.idle":"2025-06-22T09:15:45.684272Z","shell.execute_reply.started":"2025-06-22T09:15:45.662302Z","shell.execute_reply":"2025-06-22T09:15:45.683069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:45.685385Z","iopub.execute_input":"2025-06-22T09:15:45.685722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Scaling features\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Linear Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred= model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error \nrmse_linear = np.sqrt(mean_squared_error(y_test,y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rmse_linear","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Calculate and plot residuals","metadata":{}},{"cell_type":"code","source":"test_residuals = y_test - y_pred\n\nplt.figure(figsize=(8,6))\nsns.scatterplot(x=y_test, y=test_residuals, color='purple', alpha=0.6)\nplt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n\nplt.title(\"Residual Plot\")\nplt.xlabel(\"Actual Charges\")\nplt.ylabel(\"Residuals (Actual - Predicted)\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Conclusion\n*The residual plot shows that our linear regression model is not predicting well for people with very high medical charges. The difference between the actual and predicted values becomes bigger as the charges increase. This means the model is not able to capture some patterns in the data, especially for higher values. So, a more advanced model like polynomial regression or decision trees might work better.*","metadata":{}},{"cell_type":"markdown","source":"# **Polynomial Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Checking best degree ","metadata":{}},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-06-22T09:15:46.206667Z","shell.execute_reply.started":"2025-06-22T09:15:46.181392Z","shell.execute_reply":"2025-06-22T09:15:46.205619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Since X is already scaled \ntrain_rmse_error = []\ntest_rmse_error = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:46.207671Z","iopub.execute_input":"2025-06-22T09:15:46.208017Z","iopub.status.idle":"2025-06-22T09:15:46.225265Z","shell.execute_reply.started":"2025-06-22T09:15:46.207993Z","shell.execute_reply":"2025-06-22T09:15:46.224320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for d in range(1,10):\n    polynomial_converter = PolynomialFeatures(degree=d,include_bias = False)\n    poly_feature = polynomial_converter.fit_transform(X)\n\n    X_train, X_test, y_train, y_test = train_test_split(poly_feature, y, test_size=0.3, random_state=101)\n    \n    model = LinearRegression()\n    model.fit(X_train , y_train)\n\n    train_predi = model.predict(X_train)\n    test_predi = model.predict(X_test)\n\n    train_rmse = np.sqrt(mean_squared_error(y_train,train_predi))\n    test_rmse = np.sqrt(mean_squared_error(y_test,test_predi))\n\n    train_rmse_error.append(train_rmse)\n    test_rmse_error.append(test_rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:46.226327Z","iopub.execute_input":"2025-06-22T09:15:46.226919Z","iopub.status.idle":"2025-06-22T09:15:58.313318Z","shell.execute_reply.started":"2025-06-22T09:15:46.226886Z","shell.execute_reply":"2025-06-22T09:15:58.309909Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualize","metadata":{}},{"cell_type":"code","source":"plt.plot(train_rmse_error,label='TRAIN RMSE') \nplt.plot(test_rmse_error,label='TEST RMSE')\n\nplt.ylabel('RMSE')\nplt.xlabel('Degree of Poly')\nplt.legend()      #plt.legend() tells matplotlib to show a box with those labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.314400Z","iopub.execute_input":"2025-06-22T09:15:58.318111Z","iopub.status.idle":"2025-06-22T09:15:58.546994Z","shell.execute_reply.started":"2025-06-22T09:15:58.318071Z","shell.execute_reply":"2025-06-22T09:15:58.546203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_rmse_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.547961Z","iopub.execute_input":"2025-06-22T09:15:58.548206Z","iopub.status.idle":"2025-06-22T09:15:58.555013Z","shell.execute_reply.started":"2025-06-22T09:15:58.548186Z","shell.execute_reply":"2025-06-22T09:15:58.554132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_rmse_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.556009Z","iopub.execute_input":"2025-06-22T09:15:58.556295Z","iopub.status.idle":"2025-06-22T09:15:58.580956Z","shell.execute_reply.started":"2025-06-22T09:15:58.556275Z","shell.execute_reply":"2025-06-22T09:15:58.579769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create DataFrame\nrmse_df = pd.DataFrame({\n    'Degree': list(range(1, 10)),\n    'Train_RMSE': train_rmse_error,\n    'Test_RMSE': test_rmse_error\n})\n\n# Display\nrmse_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.582257Z","iopub.execute_input":"2025-06-22T09:15:58.582565Z","iopub.status.idle":"2025-06-22T09:15:58.613703Z","shell.execute_reply.started":"2025-06-22T09:15:58.582541Z","shell.execute_reply":"2025-06-22T09:15:58.612657Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Degree 2 provides the best fit.\n* It achieves a low test RMSE without overfitting, unlike higher degrees which reduce training error but significantly increase testing error, indicating overfitting.\n\n#### **Conclusion:** *Polynomial Regression (Degree 2) performed better than Linear Regression (Degree 1 by achieving a lower RMSE on the test set.*","metadata":{}},{"cell_type":"markdown","source":"# K-Nearest Neighbors (KNN) ","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.614631Z","iopub.execute_input":"2025-06-22T09:15:58.614985Z","iopub.status.idle":"2025-06-22T09:15:58.645416Z","shell.execute_reply.started":"2025-06-22T09:15:58.614947Z","shell.execute_reply":"2025-06-22T09:15:58.644508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#defining deatures and targets \nX = df.drop('charges',axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.646560Z","iopub.execute_input":"2025-06-22T09:15:58.646912Z","iopub.status.idle":"2025-06-22T09:15:58.669763Z","shell.execute_reply.started":"2025-06-22T09:15:58.646880Z","shell.execute_reply":"2025-06-22T09:15:58.668458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y=df['charges']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.670977Z","iopub.execute_input":"2025-06-22T09:15:58.671351Z","iopub.status.idle":"2025-06-22T09:15:58.693425Z","shell.execute_reply.started":"2025-06-22T09:15:58.671319Z","shell.execute_reply":"2025-06-22T09:15:58.692307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.694312Z","iopub.execute_input":"2025-06-22T09:15:58.694645Z","iopub.status.idle":"2025-06-22T09:15:58.726349Z","shell.execute_reply.started":"2025-06-22T09:15:58.694614Z","shell.execute_reply":"2025-06-22T09:15:58.725215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.731711Z","iopub.execute_input":"2025-06-22T09:15:58.732145Z","iopub.status.idle":"2025-06-22T09:15:58.754320Z","shell.execute_reply.started":"2025-06-22T09:15:58.732122Z","shell.execute_reply":"2025-06-22T09:15:58.753345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Scaling features\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.755478Z","iopub.execute_input":"2025-06-22T09:15:58.755908Z","iopub.status.idle":"2025-06-22T09:15:58.776773Z","shell.execute_reply.started":"2025-06-22T09:15:58.755843Z","shell.execute_reply":"2025-06-22T09:15:58.775525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\nscaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.777774Z","iopub.execute_input":"2025-06-22T09:15:58.778063Z","iopub.status.idle":"2025-06-22T09:15:58.809729Z","shell.execute_reply.started":"2025-06-22T09:15:58.778034Z","shell.execute_reply":"2025-06-22T09:15:58.808549Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Choosing the best K\n* KNeighborsClassifier → for classification tasks\n* KNeighborsRegressor → for regression tasks","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\ntest_rmse_errors = []\n\nfor k in range(1, 30):\n    knn_model = KNeighborsRegressor(n_neighbors=k)\n    knn_model.fit(scaled_X_train, y_train)\n    y_pred_test = knn_model.predict(scaled_X_test)\n    \n    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n    test_rmse_errors.append(rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:58.810934Z","iopub.execute_input":"2025-06-22T09:15:58.811367Z","iopub.status.idle":"2025-06-22T09:15:59.236955Z","shell.execute_reply.started":"2025-06-22T09:15:58.811326Z","shell.execute_reply":"2025-06-22T09:15:59.235829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Plot Error vs. K","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6),dpi=200)\nplt.plot(range(1,30),test_rmse_errors,label='Test Error')\nplt.legend()\nplt.ylabel('Error Rate')\nplt.xlabel(\"K Value\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:59.237826Z","iopub.execute_input":"2025-06-22T09:15:59.238095Z","iopub.status.idle":"2025-06-22T09:15:59.549016Z","shell.execute_reply.started":"2025-06-22T09:15:59.238075Z","shell.execute_reply":"2025-06-22T09:15:59.547744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_rmse_errors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:59.550231Z","iopub.execute_input":"2025-06-22T09:15:59.550538Z","iopub.status.idle":"2025-06-22T09:15:59.557491Z","shell.execute_reply.started":"2025-06-22T09:15:59.550514Z","shell.execute_reply":"2025-06-22T09:15:59.556511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Once you have a good idea of which range of k works best (say, 5–10), now you:\n* Automate finding the best k.\n* Use cross-validation for more reliable evaluation.\n* Combine scaling + modeling in one unit (Pipeline).","metadata":{}},{"cell_type":"markdown","source":"### Pipeline + GridSearchCV for KNN Regression","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nknn = KNeighborsRegressor()\n\noperations = [('scaler',scaler),('knn',knn)]\nfrom sklearn.pipeline import Pipeline\npipe = Pipeline(operations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:59.559026Z","iopub.execute_input":"2025-06-22T09:15:59.559395Z","iopub.status.idle":"2025-06-22T09:15:59.579478Z","shell.execute_reply.started":"2025-06-22T09:15:59.559371Z","shell.execute_reply":"2025-06-22T09:15:59.578516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nk_values = list(range(1, 20))\nparam_grid = {'knn__n_neighbors': k_values}\n\ngrid_model = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_root_mean_squared_error')\ngrid_model.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:15:59.580672Z","iopub.execute_input":"2025-06-22T09:15:59.581012Z","iopub.status.idle":"2025-06-22T09:16:00.596279Z","shell.execute_reply.started":"2025-06-22T09:15:59.580980Z","shell.execute_reply":"2025-06-22T09:16:00.595346Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. Check the Best Parameters Found by GridSearch","metadata":{}},{"cell_type":"code","source":"print(\"Best k value:\", grid_model.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.597235Z","iopub.execute_input":"2025-06-22T09:16:00.597517Z","iopub.status.idle":"2025-06-22T09:16:00.603425Z","shell.execute_reply.started":"2025-06-22T09:16:00.597496Z","shell.execute_reply":"2025-06-22T09:16:00.602145Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### View the Best Score (lowest RMSE)","metadata":{}},{"cell_type":"code","source":"print(\"Best CV RMSE:\", -grid_model.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.604455Z","iopub.execute_input":"2025-06-22T09:16:00.604812Z","iopub.status.idle":"2025-06-22T09:16:00.628258Z","shell.execute_reply.started":"2025-06-22T09:16:00.604780Z","shell.execute_reply":"2025-06-22T09:16:00.627297Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make Predictions on Test Set","metadata":{}},{"cell_type":"code","source":"y_pred = grid_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.629347Z","iopub.execute_input":"2025-06-22T09:16:00.629703Z","iopub.status.idle":"2025-06-22T09:16:00.658994Z","shell.execute_reply.started":"2025-06-22T09:16:00.629673Z","shell.execute_reply":"2025-06-22T09:16:00.657915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate Model Performance on Test Set","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\nknn_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\nknn_r2 = r2_score(y_test, y_pred)\n\nprint(\"Test RMSE:\", knn_rmse)\nprint(\"Test R² Score:\", knn_r2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.660161Z","iopub.execute_input":"2025-06-22T09:16:00.660494Z","iopub.status.idle":"2025-06-22T09:16:00.675533Z","shell.execute_reply.started":"2025-06-22T09:16:00.660467Z","shell.execute_reply":"2025-06-22T09:16:00.674404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Calculate and plot Residuals","metadata":{}},{"cell_type":"code","source":"residuals = y_test - y_pred\nplt.figure(figsize=(10,6), dpi=100)\nplt.scatter(y_test, residuals, color='purple', alpha=0.6)\nplt.axhline(y=0, color='red', linestyle='--')\nplt.xlabel(\"Actual Values\")\nplt.ylabel(\"Residuals (Actual - Predicted)\")\nplt.title(\"Residuals vs Actual Values\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.676501Z","iopub.execute_input":"2025-06-22T09:16:00.676755Z","iopub.status.idle":"2025-06-22T09:16:00.930075Z","shell.execute_reply.started":"2025-06-22T09:16:00.676737Z","shell.execute_reply":"2025-06-22T09:16:00.928913Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Conclusion**: model is good at predicting small numbers, but it's very bad at predicting large numbers. The bigger the true value is, the bigger the potential error of your model's prediction will be.","metadata":{}},{"cell_type":"markdown","source":"# **Support Vector Regression (SVR)**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.931469Z","iopub.execute_input":"2025-06-22T09:16:00.931812Z","iopub.status.idle":"2025-06-22T09:16:00.945393Z","shell.execute_reply.started":"2025-06-22T09:16:00.931778Z","shell.execute_reply":"2025-06-22T09:16:00.944288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#defining deatures and targets \nX = df.drop('charges',axis=1)\ny=df['charges']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.946607Z","iopub.execute_input":"2025-06-22T09:16:00.946915Z","iopub.status.idle":"2025-06-22T09:16:00.967567Z","shell.execute_reply.started":"2025-06-22T09:16:00.946874Z","shell.execute_reply":"2025-06-22T09:16:00.966401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:00.968685Z","iopub.execute_input":"2025-06-22T09:16:00.969036Z","iopub.status.idle":"2025-06-22T09:16:00.999217Z","shell.execute_reply.started":"2025-06-22T09:16:00.969003Z","shell.execute_reply":"2025-06-22T09:16:00.998012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train - test - split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:01.000680Z","iopub.execute_input":"2025-06-22T09:16:01.001114Z","iopub.status.idle":"2025-06-22T09:16:01.027936Z","shell.execute_reply.started":"2025-06-22T09:16:01.001078Z","shell.execute_reply":"2025-06-22T09:16:01.026705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pipeline SetUp","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\n\n# Pipeline: Scaling + SVR\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('svr', SVR())\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:01.029002Z","iopub.execute_input":"2025-06-22T09:16:01.029328Z","iopub.status.idle":"2025-06-22T09:16:01.049560Z","shell.execute_reply.started":"2025-06-22T09:16:01.029295Z","shell.execute_reply":"2025-06-22T09:16:01.048411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We use a Pipeline to combine scaling and modeling steps.\nIt helps in:\n\n* Keeping code clean and organized\n* Preventing data leakage during scaling\n* Ensuring proper preprocessing during cross-validation\n* Making GridSearchCV easier to apply","metadata":{}},{"cell_type":"markdown","source":"### GridSearchCV with RMSE Scoing\nWe use `GridSearchCV` to try different combinations of hyperparameters.  \nIt applies **5-fold cross-validation** and selects the best performing model based on **Root Mean Squared Error (RMSE)**.","metadata":{}},{"cell_type":"markdown","source":"In a Pipeline, you must use the format **'stepname__parameter'** when specifying parameters in param_grid for GridSearchCV.\nThe prefix **svr__** comes from the name you gave to that step in the pipeline ('svr'), followed by __ and the parameter name.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'svr__C': [0.001, 0.01, 0.1, 0.5, 1],\n    'svr__kernel': ['linear', 'rbf', 'poly'],\n    'svr__gamma': ['scale', 'auto'],\n    'svr__degree': [2, 3, 4],\n    'svr__epsilon': [0, 0.01, 0.1, 0.5, 1, 2]\n}\n\ngrid = GridSearchCV(pipe, param_grid, scoring='neg_root_mean_squared_error', cv=5)\ngrid.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:16:01.050679Z","iopub.execute_input":"2025-06-22T09:16:01.050977Z","iopub.status.idle":"2025-06-22T09:17:39.905626Z","shell.execute_reply.started":"2025-06-22T09:16:01.050954Z","shell.execute_reply":"2025-06-22T09:17:39.904811Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### cv=5, it means:\n* The training data is split into 5 equal parts (folds).\n* The model is trained on 4 parts and tested on the remaining 1 part.\n* This process is repeated 5 times, each time with a different test fold.\n* The final performance score is the average across all 5 runs.\n\n### Why `cv=5`?\n- Performs 5-fold cross-validation for more **reliable model evaluation**.\n- Helps reduce overfitting and gives better hyperparameter tuning.\n- Not mandatory, but **highly recommended**.\n\n### scoring='neg_root_mean_squared_error'\nScikit-learn’s GridSearchCV tries to maximize the scoring value to choose the best model.\nHowever, lower RMSE (Root Mean Squared Error) actually means better performance.\nWe are still minimizing RMSE, just expressed in a way that works with scikit-learn's logic.","metadata":{}},{"cell_type":"markdown","source":"### Evaluate Best Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Best Estimator\nbest_model = grid.best_estimator_\ny_pred = best_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:17:39.906984Z","iopub.execute_input":"2025-06-22T09:17:39.907411Z","iopub.status.idle":"2025-06-22T09:17:39.925915Z","shell.execute_reply.started":"2025-06-22T09:17:39.907382Z","shell.execute_reply":"2025-06-22T09:17:39.924570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation\nmae_svr = mean_absolute_error(y_test, y_pred)\nrmse_svr = np.sqrt(mean_squared_error(y_test, y_pred))\n\nprint(\"Best Parameters:\", grid.best_params_)\nprint(\"MAE:\", mae_svr)\nprint(\"RMSE:\", rmse_svr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:17:39.927302Z","iopub.execute_input":"2025-06-22T09:17:39.927612Z","iopub.status.idle":"2025-06-22T09:17:39.948998Z","shell.execute_reply.started":"2025-06-22T09:17:39.927588Z","shell.execute_reply":"2025-06-22T09:17:39.947555Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### What we found:\n* The linear kernel performed best among the tested ones (linear, rbf, poly).\n* The model's predictions deviate by about ₹11.8k on average. Given the mean charge (~₹13.2k), the error is moderate. SVR performs decently but there’s room for improvement.","metadata":{}},{"cell_type":"markdown","source":"### Calculate and Plot residuals","metadata":{}},{"cell_type":"code","source":"residuals = y_test - y_pred\nplt.figure(figsize=(10,6), dpi=100)\nplt.scatter(y_test, residuals, color='purple', alpha=0.6)\nplt.axhline(y=0, color='red', linestyle='--')\nplt.xlabel(\"Actual Values\")\nplt.ylabel(\"Residuals (Actual - Predicted)\")\nplt.title(\"Residuals vs Actual Values\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:17:39.950352Z","iopub.execute_input":"2025-06-22T09:17:39.950656Z","iopub.status.idle":"2025-06-22T09:17:40.204999Z","shell.execute_reply.started":"2025-06-22T09:17:39.950632Z","shell.execute_reply":"2025-06-22T09:17:40.203950Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Conclusion:**\nThe residuals are *not randomly scattered around zero* — instead, they form a clear linear pattern.\nThis indicates:\n* The SVR model is consistently underpredicting for high actual values.\n* There may be non-linear relationships in the data that the current SVR model (likely with a linear kernel) isn't capturing effectively.\n\nA g**ood model should show no pattern in residuals** (random scatter), which suggests constant error variance and that the model fits the data well.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}